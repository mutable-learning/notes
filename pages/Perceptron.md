tags:: Algorithmics
topic:: [[Neural Network]]
algo:: Unit 4 Outcome 3

-
- A multilayer perceptron (MLP) is a feedforward artificial neural network (ANN) that consists of multiple layers of interconnected nodes. The nodes in each layer are connected to the nodes in the next layer, and the connections have weights that are adjusted during training.
- The MLP has three main layers:
	- The input layer: This layer receives the input data.
	- The hidden layer(s): This layer(s) performs the actual computation. The number of hidden layers can be one or more.
	- The output layer: This layer produces the output of the network.
- The nodes in each layer are called neurons. Each neuron has a weighted sum of the inputs from the previous layer, and an activation function that determines the output of the neuron. The activation function is a non-linear function that allows the MLP to learn more complex relationships between the input and output data.
- The MLP is trained using a supervised learning algorithm. This means that the network is given a set of training data, where each data point consists of an input vector and an output vector. The network learns to map the input vectors to the output vectors by adjusting the weights between the neurons.
- ![Mult-layer Perceptron](https://i.stack.imgur.com/5SkqL.png)
- The MLP is trained by adjusting the weights so that the output of the network is as close as possible to the desired output for the given input. This is done using a supervised learning algorithm, such as backpropagation.
- MLPs are a versatile and powerful tool for machine learning. They can be used to solve a variety of problems, including classification, regression, and time series forecasting.
-
- Further Research
  background-color:: purple
	- Read
		- a
	- Watch
		- b